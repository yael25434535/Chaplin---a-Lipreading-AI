# -*- coding: utf-8 -*-
"""modelsProofOfConcept.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16ZCjaNz2y3xkGzmIOUlWByYxdV1x5GMD

<h1><center> Visual Speech Recognition || Yael Sasson </center></h1>

## 📦 Importing Libraries
"""

!pip install numpy==1.26.4
!pip install --upgrade evaluate jiwer
#!pip instal==gdown

import os
import cv2
import tensorflow as tf
import numpy as np
from typing import List
from matplotlib import pyplot as plt
import imageio
import gdown
import json

url = 'https://drive.google.com/uc?id=17GBUYiaZGdIldzCVK1e_b4H43xTxj1U5'
output = 'ml_project.zip'
gdown.download(url, output, quiet=True)
gdown.extractall('ml_project.zip')

"""<div dir="rtl">

 **`vocab`** מכיל רשימה של כל התווים האפשריים שיכולים להיאמר על ידי הדוברים  (אותיות אנגלית, סימנים מסוימים ומספרים).  
לאחר מכן, **`char_to_num`** נעשה בעזרת `StringLookup` של Keras שממירה כל תו למספר לפי הסדר המופיע ב-`vocab`.  
**`num_to_char`** מבצע את הפעולה ההפוכה – ממיר מספרים חזרה לאותיות.  


</div>

"""

vocab = list("abcdefghijklmnopqrstuvwxyz'?!123456789 ")

char_to_num = tf.keras.layers.StringLookup(vocabulary=vocab, oov_token="")
num_to_char = tf.keras.layers.StringLookup(vocabulary=char_to_num.get_vocabulary(), oov_token="", invert=True)

print("The vocabulary is:", char_to_num.get_vocabulary())
print("size:", char_to_num.vocabulary_size())

"""<div dir="rtl">

פונקציה לעיבוד המשפטים שנאמרו בכל סרטון

הפונקציה קוראת את קובץ txt, עוברת על כל שורה, ומחלצת ממנה את המילים תוך התעלמות מהמופעים של `'sil'` או  `'sp'`   
בכל שורה, נבדקת המילה השלישית, ואם היא לא `'sil'`, היא מתווספת לרשימה עם רווח לפניה.  
לאחר מכן, הרשימה מומרת לטנזור של TensorFlow, ומועברת דרך `char_to_num` להמרת האותיות למספרים.  
לבסוף, התוצאה מחזירה את הטוקנים, המילים, שחולצו כמספרים  

</div>

"""

def extract_alignment(align_path):
    with open(align_path, 'r') as f:
        lines = f.readlines()
    tokens = []
    for line in lines:
        line = line.split()
        if line[2] not in ['sil', 'sp']:
          tokens = [*tokens,' ',line[2]]

    # Convert to TensorFlow Tensor
    token_tensor = tf.strings.unicode_split(tokens, input_encoding='UTF-8')
    return char_to_num(tf.reshape(token_tensor, (-1)))[1:]  # Remove the first element (always 'sil')

"""
<div dir="rtl">

מקבלת  path, ובעזרתו מוצאת את הpaths של הסרטון ושל המשפט המתאים לו.  
לאחר מכן, משתמשת בפונקציה שמעבדת את הסרטון להמרתו לפריימים, ובפונקציה שמעבדת את קובצי הטקסט כדי לחלץ את המילים ומחזירה הן את הפריימים והן את הalignments  

</div>

"""

def load_data(path):
    path = bytes.decode(path.numpy())
    file_name = path.split('/')[-1].split('.')[0]

    # Load preprocessed frames
    #frames_path = os.path.join('ml_project','model1','processed_100x50', f'{file_name}.npy')
    frames_path = os.path.join('ml_project','model2','processed_70x40', f'{file_name}.npy')

    frames = tf.convert_to_tensor(np.load(frames_path), dtype=tf.float32)

    # Load alignment
    alignment_path = os.path.join('ml_project','align',f'{file_name}.align')
    alignments =  extract_alignment(alignment_path)

    return frames, alignments

"""##🗄️Data Pipeline

<div dir="rtl">

נכין את הדאטה.  
תחילה, ניצור רשימה של כל קובצי הסרטונים, נערבב (shuffle) אותם, ונמיר כל `path` לפריימים ולמשפט שנאמר.  
נשתמש ב-`padded_batch` כך ש:  

- פריימים ירופדו לאורך מקסימלי של **75**.  
- ייצוג המילים ירופד לאורך מקסימלי של **40**.  

לבסוף, נבצע **prefetch** לייעול התהליך, ונחלק את הנתונים כך ש-1800 דוגמאות ישמשו ל-`train`, והשאר ל-`test`, באמצעות השיטות `take` ו-`skip`.  

</div>
"""

def mappable_function(path):
    result = tf.py_function(load_data, [path], (tf.float32, tf.int64))
    return result

'''
data1 =  tf.data.Dataset.list_files('./ml_project/align/*.align')
data1 = data1.shuffle(500, reshuffle_each_iteration=False)
data1 = data1.map(mappable_function)
data1 = data1.padded_batch(2, padded_shapes=([75,None,None, None],[40]))
data1 = data1.prefetch(tf.data.AUTOTUNE)
train1 = data1.take(450)
test1 = data1.skip(450)
'''

data2 = tf.data.Dataset.list_files('./ml_project/align/*.align')
data2 = data2.shuffle(500, reshuffle_each_iteration=False)
data2 = data2.map(mappable_function)
data2 = data2.padded_batch(2, padded_shapes=([75,None,None, None],[40]))
data2 = data2.prefetch(tf.data.AUTOTUNE)
train2 = data2.take(450)
test2 = data2.skip(450)

# Create directories for saving datasets
#save_dir = './saved_datasets1'
save_dir = './saved_datasets2'
os.makedirs(save_dir, exist_ok=True)

#train1.save(os.path.join(save_dir, 'train1'))
#test1.save(os.path.join(save_dir, 'test1'))
train2.save(os.path.join(save_dir, 'train2'))
test2.save(os.path.join(save_dir, 'test2'))

import shutil

# Create a ZIP archive of saved datasets
#shutil.make_archive('saved_datasets1', 'zip', 'saved_datasets1')
shutil.make_archive('saved_datasets2', 'zip', 'saved_datasets2')

'''
sample = data1.as_numpy_iterator()
val = sample.next(); val[0]
plt.imshow(val[0][0][35])
tf.strings.reduce_join([num_to_char(word) for word in val[1][0]])
'''

sample = data2.as_numpy_iterator()
val = sample.next(); val[0]
plt.imshow(val[0][0][35])
tf.strings.reduce_join([num_to_char(word) for word in val[1][0]])

"""## 🛠️ Model Building

<div dir="rtl">

מייבא את הספריות הנדרשות לבניית המודל

</div>
"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import (Conv3D, Dense, Dropout, Bidirectional,
                                     MaxPool3D, Activation, Reshape, SpatialDropout3D,
                                     BatchNormalization, TimeDistributed, Flatten,
                                     GlobalAveragePooling3D, GRU)
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping

"""<div dir="rtl">
המימדים עבור סרטון יחיד
</div>
"""

#inputshape1 = data1.as_numpy_iterator().next()[0][0].shape
inputshape2 = data2.as_numpy_iterator().next()[0][0].shape

"""<div dir="rtl">

ארכיטקטורת המודל שלי
</div>

"""

'''
model = Sequential()
model.add(Conv3D(128, (3, 3, 3), input_shape=inputshape1, padding='same'))
model.add(Activation('relu'))
model.add(MaxPool3D((1, 2, 2)))

model.add(Conv3D(256, (3, 3, 3), padding='same'))
model.add(Activation('relu'))
model.add(MaxPool3D((1, 2, 2)))

model.add(Conv3D(75, (3, 3, 3), padding='same'))
model.add(Activation('relu'))
model.add(MaxPool3D((1, 2, 2)))

model.add(Reshape((75, -1)))
model.add(Bidirectional(GRU(128, kernel_initializer='Orthogonal', return_sequences=True)))
model.add(Dropout(.5))

model.add(Bidirectional(GRU(128, kernel_initializer='Orthogonal', return_sequences=True)))
model.add(Dropout(.5))

model.add(Dense(char_to_num.vocabulary_size()+1, kernel_initializer='he_normal', activation='softmax'))
'''

'''
model.summary()
'''

model = Sequential()
model.add(Conv3D(128, (3, 3, 3), input_shape=inputshape2, padding='same'))
model.add(Activation('relu'))
model.add(MaxPool3D((1, 2, 2)))

model.add(Conv3D(256, (3, 3, 3), padding='same'))
model.add(Activation('relu'))
model.add(MaxPool3D((1, 2, 2)))

model.add(Conv3D(75, (3, 3, 3), padding='same'))
model.add(Activation('relu'))
model.add(MaxPool3D((1, 2, 2)))

model.add(Reshape((75, -1)))
model.add(Bidirectional(GRU(128, kernel_initializer='Orthogonal', return_sequences=True)))
model.add(Dropout(.5))

model.add(Bidirectional(GRU(128, kernel_initializer='Orthogonal', return_sequences=True)))
model.add(Dropout(.5))

model.add(Dense(char_to_num.vocabulary_size()+1, kernel_initializer='he_normal', activation='softmax'))

model.summary()

"""## ⭐ Setup Training Options

<div dir="rtl">

הגדרת פונקציית ההפסד

</div>
"""

def CTCLoss(y_true, y_pred):
    batch_len = tf.cast(tf.shape(y_true)[0], dtype="int64")  # Batch size
    input_length = tf.cast(tf.shape(y_pred)[1], dtype="int64")  # Length of the input sequence (number of frames)
    label_length = tf.cast(tf.shape(y_true)[1], dtype="int64")  # Length of the target sequence (number of characters)

    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype="int64")  # Expand input length for each sample in the batch
    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype="int64")  # Expand label length for each sample in the batch

    loss = tf.keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)  # Compute the CTC loss
    return loss  # Return the loss value

"""<div dir="rtl">

מגדירה  Callback שמדפיסה דוגמאות מקוריות וניבוי של המודל בסוף כל אפוק.  

</div>

"""

class ProduceExample(tf.keras.callbacks.Callback):
    def __init__(self, dataset):
        self.dataset = dataset.as_numpy_iterator()

    def on_epoch_end(self, epoch, logs=None):
        data = self.dataset.next()
        yhat = self.model.predict(data[0])  # Predict the output based on the input frames

        # Decode predictions using CTC decoding (beam search)
        decoded = tf.keras.backend.ctc_decode(yhat, [75, 75], greedy=False)[0][0].numpy()

        # Print original and predicted text for each example in the batch
        for x in range(len(yhat)):
            print('Original:', tf.strings.reduce_join(num_to_char(data[1][x])).numpy().decode('utf-8'))
            print('Prediction:', tf.strings.reduce_join(num_to_char(decoded[x])).numpy().decode('utf-8'))
            print('~' * 100)

"""<div dir="rtl">

קומפילציה של המודל עם האופטימיזטור `Adam` ופונקציית ההפסד `CTCLoss`.  
האופטימיזטור `Adam` משתמש בקצב למידה של **0.0001**

</div>

"""

model.compile(optimizer=Adam(learning_rate=0.0001), loss=CTCLoss)

"""## 🚀 Model 1 Training"""

example_callback = ProduceExample(test1)

"""<div dir="rtl">

callback לשמירת המודל הטוב ביותר

</div>

"""

local_path = "/content/model1.keras"

model_save = ModelCheckpoint(
    local_path,
    monitor='val_loss',
    save_best_only=True,  # Save only if the model improves
    save_weights_only=False,  # Save the entire model (not just weights)
    verbose=1
)

early_stopping = EarlyStopping(
    monitor='val_loss',
    patience=10,
    verbose=1,
    restore_best_weights=True
)

model.fit(train1, validation_data=test1, epochs=50, callbacks=[model_save, example_callback, early_stopping ])

"""<div dir="rtl">

שמירת ההיסטוריה בקובץ json

</div>

"""

import json
with open('historyModel1.json', 'w') as f:
    json.dump(model.history.history, f)

from google.colab import files

# After your model has been saved to local_path
files.download("/content/model1.keras")
files.download('historyModel1.json')

"""## 🚀 Model 2 Training"""

example_callback = ProduceExample(test2)

local_path = "/content/model2.keras"

model_save = ModelCheckpoint(
    local_path,
    monitor='val_loss',
    save_best_only=True,  # Save only if the model improves
    save_weights_only=False,  # Save the entire model (not just weights)
    verbose=1
)

early_stopping = EarlyStopping(
    monitor='val_loss',
    patience=10,
    verbose=1,
    restore_best_weights=True
)

model.fit(train2, validation_data=test2, epochs=50, callbacks=[model_save, example_callback, early_stopping ])

import json
with open('historyModel2.json', 'w') as f:
    json.dump(model.history.history, f)

from google.colab import files

# After your model has been saved to local_path
files.download("/content/model2.keras")
files.download('historyModel2.json')

"""##val"""

def load_val_data(path):
  path = bytes.decode(path.numpy())
  file_name = path.split('/')[-1].split('.')[0]
  frames_path = os.path.join('ml_project','preVal','val_70x40', f'{file_name}.npy')
  frames = tf.convert_to_tensor(np.load(frames_path), dtype=tf.float32)
  alignment_path = os.path.join('ml_project','preVal', 'align', f'{file_name}.align')
  alignments = extract_alignment(alignment_path)
  return frames, alignments



    # Create mappable function for validation data

def val_mappable_function(path):
  result = tf.py_function(load_val_data, [path], (tf.float32, tf.int64))
  return result



    # Create validation dataset
val_data = tf.data.Dataset.list_files('./ml_project/preVal/align/*.align')
val_data = val_data.map(val_mappable_function)
val_data = val_data.padded_batch(2, padded_shapes=([75, None, None, None], [40]))
val_data = val_data.prefetch(tf.data.AUTOTUNE)

"""##🔍 Evaluation"""

from tensorflow.keras.models import load_model
model1 = load_model('ml_project/model1/model1.keras', compile=True, custom_objects={'CTCLoss': CTCLoss})
model2 = load_model('ml_project/model2/model2.keras', compile=True, custom_objects={'CTCLoss': CTCLoss})

train1 = tf.data.Dataset.load('/content/ml_project/model1/train1')
test1 = tf.data.Dataset.load('/content/ml_project/model1/test1')
train2 = tf.data.Dataset.load('/content/ml_project/model2/train2')
test2 = tf.data.Dataset.load('/content/ml_project/model2/test2')

with open('ml_project/model1/historyModel1.json', 'r') as f:
    historyModel1 = json.load(f)
with open('ml_project/model2/historyModel2.json', 'r') as f:
    historyModel2 = json.load(f)

"""<div dir="rtl">
הצגת גרף של ההפסד של מודל 1 לאורך האפוקים.

</div>

"""

import matplotlib.pyplot as plt

plt.plot(historyModel1['loss'], label='Train Loss', color='pink')
plt.plot(historyModel1['val_loss'], label='Validation Loss', color='hotpink')

plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.title('Loss Over Epochs')

plt.show()

"""<div dir="rtl">
הצגת גרף של ההפסד של מודל 2 לאורך האפוקים.

</div>

"""

import matplotlib.pyplot as plt

plt.plot(historyModel2['loss'], label='Train Loss', color='pink')
plt.plot(historyModel2['val_loss'], label='Validation Loss', color='hotpink')

plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.title('Loss Over Epochs')

plt.show()

"""<div dir="rtl">

**מחשב את שיעור השגיאות של המודל באמצעות CER ו-WER.**  
- **CER (Character Error Rate)** – מחשב את שיעור השגיאות ברמת האותיות.  
- **WER (Word Error Rate)** – מחשב את שיעור השגיאות ברמת המילים.  

</div>

"""

from evaluate import load

# Load HuggingFace metrics once
wer_metric = load("wer")
cer_metric = load("cer")

def predict_from_video(model, video_tensor):
    yhat = model.predict(video_tensor, verbose=0)
    batch_size = yhat.shape[0]
    input_lengths = tf.constant([yhat.shape[1]] * batch_size)

    decoded, _ = tf.keras.backend.ctc_decode(yhat, input_length=input_lengths, greedy=True)
    decoded_sequences = decoded[0]

    results = []
    for seq in decoded_sequences:
        seq = tf.convert_to_tensor(seq)
        text = tf.strings.reduce_join(num_to_char(seq)).numpy().decode("utf-8")
        results.append(text)

    return results


def evaluate_wer_cer(model, dataset, max_batches=None, name=""):
    references = []
    predictions = []

    for i, batch in enumerate(dataset):


        x, y_true = batch
        y_preds = predict_from_video(model, x)

        for j in range(len(y_preds)):
            ref = tf.strings.reduce_join(num_to_char(y_true[j])).numpy().decode("utf-8")
            pred = y_preds[j]

            predictions.append(pred)
            references.append(ref)

    wer = wer_metric.compute(references=references, predictions=predictions)
    cer = cer_metric.compute(references=references, predictions=predictions)

    print(f"{name} Set:")
    print(f"WER: {wer:.2%}")
    print(f"CER: {cer:.2%}")
    return wer, cer

evaluate_wer_cer(model1, train1, num_to_char, name="Train on model 1")
evaluate_wer_cer(model1, test1, num_to_char, name="Test on model 1")
evaluate_wer_cer(model1, val_data, num_to_char, name="Validation on model 1")

evaluate_wer_cer(model2, train2, num_to_char, name="Train on model 2")
evaluate_wer_cer(model2, test2, num_to_char, name="Test on model 2")
evaluate_wer_cer(model2, val_data, num_to_char, name="Validation on model 2")

"""## 🚀 LightWeight architure"""

light_model = Sequential()

light_model.add(Conv3D(64, (3, 3, 3), input_shape=(75, 40, 70, 1), padding='same'))
light_model.add(Activation('relu'))
light_model.add(MaxPool3D((1, 2, 2)))

light_model.add(Conv3D(128, (3, 3, 3), padding='same'))
light_model.add(Activation('relu'))
light_model.add(MaxPool3D((1, 2, 2)))

light_model.add(Reshape((75, -1)))

light_model.add(Bidirectional(GRU(64, return_sequences=True)))
light_model.add(Dropout(0.5))

light_model.add(Dense(char_to_num.vocabulary_size() + 1, activation='softmax'))

light_model.summary()

light_model.compile(
    optimizer=Adam(learning_rate=0.0001),
    loss=CTCLoss
)
example_callback = ProduceExample(test2)

model_save = ModelCheckpoint(
    'light_model.keras',
    monitor='val_loss',
    save_best_only=True,
    verbose=1
)

early_stopping = EarlyStopping(
    monitor='val_loss',
    patience=10,
    restore_best_weights=True,
    verbose=1
)

history_light = light_model.fit(
    train2,
    validation_data=test2,
    epochs=50,
    callbacks=[model_save, example_callback, early_stopping]
)

import json
with open('historyLightModel.json', 'w') as f:
    json.dump(history_light.history, f)

with open('historyLightModel.json', 'r') as f:
    historyLightModel = json.load(f)

import matplotlib.pyplot as plt

plt.plot(historyLightModel['loss'], label='Train Loss', color='pink')
plt.plot(historyLightModel['val_loss'], label='Validation Loss', color='hotpink')

plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.title('Loss Over Epochs')

plt.show()

evaluate_wer_cer(light_model, train2, name="Train on light model")
evaluate_wer_cer(light_model, test2, name="Test on light model")
evaluate_wer_cer(light_model, val_data, name="Validation on light model")